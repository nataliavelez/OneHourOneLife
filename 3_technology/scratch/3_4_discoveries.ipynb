{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting discoveries\n",
    "Natalia VÃ©lez, July 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "import os, re, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join as opj\n",
    "\n",
    "import scipy.stats\n",
    "from gini import gini\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import notebook\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper: Extract timestamp from filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_start(f):\n",
    "    t0 = re.search('((?<=start-)|(?<=time-))[0-9]+', f).group(0)\n",
    "    return int(t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Family labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fam_file = '../2_demographics/outputs/family_playerID.tsv'\n",
    "fam_df = pd.read_csv(fam_file, sep='\\t', index_col=0)\n",
    "#fam_df = fam_df.rename(columns={'playerID':'player_id'})\n",
    "fam_df['fam_start'] = fam_df['family'].apply(file_start)\n",
    "print('Labeling players by family:')\n",
    "print(fam_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Family fitness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_file = '../2_demographics/outputs/family_fitness.tsv'\n",
    "fit_df = pd.read_csv(fit_file, sep='\\t', index_col=None)\n",
    "print('Analyzing %i families' % fit_df.shape[0])\n",
    "print(fit_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object depth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_file = 'tech_tree/num_unique_ingredients.csv'\n",
    "depth_df = pd.read_csv(depth_file)\n",
    "depth_df = depth_df.rename(columns={'id': 'object_id', 'num_ingredients': 'depth'})\n",
    "depth_df = depth_df[['object_id', 'depth']]\n",
    "print('Repertoire depth:')\n",
    "print(depth_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find map change files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch = lambda *args: glob.glob(opj(*args))\n",
    "map_dir = 'outputs/maplog/'\n",
    "\n",
    "map_files = gsearch(map_dir, '*.tsv')\n",
    "map_files.sort()\n",
    "\n",
    "print('Found %i map files' % len(map_files))\n",
    "print(*map_files[:10], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find map seed changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_file = 'outputs/seed_changes.txt'\n",
    "with open(seed_file, 'r') as handle:\n",
    "    seed_data = handle.read().splitlines()\n",
    "\n",
    "seed_changes = np.array([int(s) for s in seed_data])\n",
    "seed_changes = np.sort(seed_changes)\n",
    "\n",
    "print('%i world seeds' % len(seed_changes))\n",
    "print(seed_changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find seed file corresponding to timestamp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_seed(tstamp):\n",
    "    \n",
    "    lag = tstamp - seed_changes\n",
    "    seeds = seed_changes[lag >= 0]\n",
    "    if len(seeds):\n",
    "        seed = seeds[-1]\n",
    "    else: # Special: First log file\n",
    "        seed = seed_changes[0]\n",
    "            \n",
    "    return seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group mapchange files by world seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_df = pd.DataFrame(map_files, columns=['file'])\n",
    "file_df['tstamp'] = file_df.file.str.extract('(?<=start-)([0-9]+)')\n",
    "file_df['tstamp'] = file_df['tstamp'].astype(np.int)\n",
    "file_df['seed'] = file_df.tstamp.apply(find_seed)\n",
    "file_df = file_df.sort_values('tstamp')\n",
    "file_df['seed_start'] = file_df.groupby('seed')['tstamp'].transform('min')\n",
    "print(file_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify discoveries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function: Clean up individual map change files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_maplog(f):\n",
    "    s_df = pd.read_csv(f, sep='\\t', index_col=None)\n",
    "    #s_df = s_df.rename(columns={'player_id': 'avatar'})\n",
    "    \n",
    "    # Fix timestamps to start of world seed\n",
    "    t_log = file_start(f)\n",
    "    s_df['t_epoch'] = s_df['t_elapsed'] + t_log\n",
    "\n",
    "    # Player events only\n",
    "    s_df = s_df[s_df['avatar'] > 0]\n",
    "\n",
    "    # Parse object IDs, removing special identifiers\n",
    "    s_df['object_id'] = s_df.object_id.str.replace('(^f|v[0-9]+|u[0-9]+)', '')\n",
    "    s_df['object_id'] = s_df['object_id'].astype(np.int)\n",
    "\n",
    "    # Only interactions with valid objects\n",
    "    s_df = s_df[(s_df['object_id'] > 0) & (s_df['object_id'] < 5000)]\n",
    "    s_df = s_df[s_df['object_id'] != 87] # Exclude fresh graves (player deaths)\n",
    "\n",
    "    # Tag players by family    \n",
    "    s_df = pd.merge(s_df, fam_df, on='avatar')\n",
    "    s_df['t_fam'] = s_df['t_epoch'] - s_df['fam_start'] # t=0 at Eve birth\n",
    "\n",
    "    return s_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify discoveries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_discoveries(maplog):\n",
    "\n",
    "    # Prepare dataframe\n",
    "    discoveries = maplog.copy()\n",
    "    discoveries = discoveries[['seed', 't_epoch', 't_fam','family', 'object_id', 'x', 'y', 'avatar']]\n",
    "    discoveries = discoveries.sort_values('t_fam')\n",
    "\n",
    "    # Find the first time an object appears in family's repertoire\n",
    "    discoveries = discoveries.groupby(['seed', 'family', 'object_id']).first()\n",
    "    discoveries = discoveries.reset_index()\n",
    "    discoveries = pd.merge(discoveries, depth_df)\n",
    "    discoveries = discoveries.sort_values(['family', 't_fam'])\n",
    "\n",
    "    return discoveries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change in repertoire size over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discoveries_dynamic(discoveries):\n",
    "    disc_count = discoveries.copy()\n",
    "    disc_count = disc_count.sort_values(['family', 't_epoch'])\n",
    "    disc_count['is_obj'] = (disc_count['object_id'] > 0)*1\n",
    "    disc_count['count'] = disc_count.groupby('family')['is_obj'].cumsum()\n",
    "    disc_count = disc_count[['seed', 'family', 'object_id', 't_epoch', 'count']]\n",
    "    disc_count = disc_count.reset_index(drop=True)\n",
    "    return disc_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count # of discoveries per player:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorenz_inputs(discoveries):\n",
    "    # Return a count of # discoveries for each family member\n",
    "    n_discoveries = discoveries.groupby(['family','avatar'])['object_id']\n",
    "    n_discoveries = n_discoveries.agg('count').reset_index()\n",
    "    n_discoveries = n_discoveries.rename(columns={'object_id': 'n'})\n",
    "\n",
    "    # Fill in missing family members (no discoveries)\n",
    "    log_fams = np.unique(discoveries['family'])\n",
    "    all_fam = fam_df.copy()\n",
    "    all_fam = all_fam[['family', 'avatar']]\n",
    "    all_fam = all_fam[all_fam['family'].isin(log_fams)].reset_index(drop=True)\n",
    "\n",
    "    # Total number of discoveries\n",
    "    n_discoveries_full = pd.merge(all_fam, n_discoveries, how='outer')\n",
    "    n_discoveries_full['n'] = n_discoveries_full['n'].fillna(0).astype(int)\n",
    "    \n",
    "    # Family totals\n",
    "    fam_totals = n_discoveries_full.groupby('family')['n'].agg(['sum', 'count']).reset_index()\n",
    "    n_discoveries_full = pd.merge(n_discoveries_full, fam_totals, on='family', how='outer')\n",
    "    n_discoveries_full = n_discoveries_full.sort_values(['family', 'n'], ascending=True)\n",
    "    \n",
    "    # Cumulative players and discoveries\n",
    "    n_discoveries_full['cum_players'] = n_discoveries_full.groupby('family')['n'].cumcount()+1\n",
    "    n_discoveries_full['cum_players'] = n_discoveries_full['cum_players']/n_discoveries_full['count']\n",
    "    \n",
    "    n_discoveries_full['cum_discoveries'] = n_discoveries_full.groupby('family')['n'].cumsum()\n",
    "    n_discoveries_full['cum_discoveries'] = n_discoveries_full['cum_discoveries']/n_discoveries_full['sum']\n",
    "    \n",
    "    return n_discoveries_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Lorenz curves (used to visualize innovation inequality):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Lorenz curve\n",
    "def plot_lorenz(in_df, name, seed):\n",
    "    highlight_col = '#ffad3b'\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    \n",
    "    # Insert point at origin \n",
    "    origin = pd.DataFrame({'family': [name],\n",
    "                           'avatar': [0],\n",
    "                           'n': [0],\n",
    "                           'sum': [0],\n",
    "                           'count': [0],\n",
    "                           'cum_players': [0],\n",
    "                           'cum_discoveries': [0]})\n",
    "    \n",
    "    df = pd.concat([origin, in_df])\n",
    "    # Cumulative distribution\n",
    "    sns.lineplot(data = df, x = 'cum_players', y = 'cum_discoveries', color = highlight_col, ax=ax)\n",
    "\n",
    "    # Fill in area over Lorenz curve\n",
    "    ax.fill_between(df['cum_players'], df['cum_discoveries'], df['cum_players'],\n",
    "                   color = highlight_col)\n",
    "\n",
    "    # Write Gini coefficient on plot\n",
    "    g = gini(df['cum_discoveries'].values)\n",
    "    ax.text(0.75, 0.05, 'G = %.2f' % g, \n",
    "            bbox = {'facecolor': '#ffffff', 'edgecolor': highlight_col})\n",
    "\n",
    "    # Line of equality\n",
    "    ax.plot([0, 1], [0, 1], transform=ax.transAxes, linestyle='-', color='black', linewidth = 1) \n",
    "\n",
    "    ## Customize\n",
    "    ax.yaxis.tick_right() # Move axes to the right\n",
    "    ax.tick_params(axis = \"y\", which = \"both\", right = False)\n",
    "\n",
    "    ax.yaxis.set_label_position(\"right\")\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "\n",
    "    ax.set(xlim = [0,1], ylim= [0,1], aspect = 1.0,\n",
    "           xlabel='Cumulative share of characters\\n(Fewest to most discoveries)',\n",
    "           ylabel='Cumulative share of discoveries')\n",
    "\n",
    "    #  Save to file\n",
    "    plot_file = 'plots/discoveries/seed-%i_%s_lorenz.png' % (seed, name)\n",
    "    plt.savefig(plot_file, bbox_inches = 'tight')\n",
    "    plt.close()\n",
    "        \n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot distribution of # discoveries (useful to interpret Lorenz curve):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dist(df, name, seed):\n",
    "    ax = sns.distplot(df['n'], kde=False)\n",
    "    ax.set(xlabel='# discoveries')\n",
    "    sns.despine()\n",
    "    \n",
    "    plot_file = 'plots/discoveries/seed-%i_%s_dist.png' % (seed, name)\n",
    "    plt.savefig(plot_file, bbox_inches = 'tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discovery_list = []\n",
    "rep_list = []\n",
    "gini_list = []\n",
    "\n",
    "for s in notebook.tqdm(seed_changes):\n",
    "    # Identify all logs with the same world seed\n",
    "    seed_logs = file_df[file_df['seed'] == s].copy()\n",
    "    seed_fs = seed_logs['file'].values\n",
    "\n",
    "    if len(seed_fs):\n",
    "\n",
    "        # Add all logs associated with the same world seed to dataframe\n",
    "        seed_list = [process_maplog(f) for f in seed_fs]\n",
    "        seed_df = pd.concat(seed_list).reset_index(drop=True)\n",
    "        seed_df['seed'] = s\n",
    "\n",
    "        # Identify discoveries by family\n",
    "        # = first time a family member interacts with an object, by world seed\n",
    "        seed_disc = id_discoveries(seed_df)\n",
    "        \n",
    "        # Change in repertoire size over time (used for survival regression)\n",
    "        seed_disc_time = discoveries_dynamic(seed_disc)\n",
    "\n",
    "        # Cumulative counts (used to plot Lorenz curve)\n",
    "        seed_disc_cum = lorenz_inputs(seed_disc)\n",
    "        seed_disc_cum['seed'] = s\n",
    "\n",
    "        # Depth and breadth of repertoire\n",
    "        seed_repertoire = seed_disc.groupby('family').agg({'object_id': 'count', 'depth': 'max'}).reset_index()\n",
    "        seed_repertoire = seed_repertoire.rename(columns={'object_id': 'breadth'})\n",
    "\n",
    "        # Innovation inequality\n",
    "        for name,group in notebook.tqdm(seed_disc_cum.groupby('family')):    \n",
    "\n",
    "            g = plot_lorenz(group, name, s)\n",
    "            plot_dist(group, name, s)\n",
    "            gini_list.append((s, name, g))\n",
    "\n",
    "        # Add to lists\n",
    "        discovery_list.append(seed_disc_time)\n",
    "        rep_list.append(seed_repertoire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_df = pd.concat(rep_list)\n",
    "rep_df['log_breadth'] = np.log10(rep_df['breadth'])\n",
    "rep_df['log_depth'] = np.log10(rep_df['depth'])\n",
    "rep_df.to_csv('outputs/family_repertoire.tsv', sep='\\t', index=False)\n",
    "#rep_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_df = pd.DataFrame(gini_list, columns = ['seed', 'family', 'gini'])\n",
    "gini_df.to_csv('outputs/family_gini.tsv', sep='\\t', index=False)\n",
    "#gini_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discovery_df = pd.concat(discovery_list)\n",
    "discovery_df.to_csv('outputs/family_discoveries.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot innovation inequality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = sns.distplot(gini_df['gini'])\n",
    "# ax.set(xlabel='Innovation inequality (G)', xlim=(0,1))\n",
    "# sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relationship between G and community size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size_df = pd.read_csv('../2_demographics/outputs/family_fitness.tsv', sep='\\t', index_col=None)\n",
    "# size_df = size_df[['family', 'sum']]\n",
    "# size_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_size = pd.merge(gini_df, size_df, on='family', how='outer')\n",
    "# g_size['log_sum'] = np.log10(g_size['sum'])\n",
    "# g_size.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(6,6))\n",
    "# ax = sns.regplot(x='gini', y='log_sum', data=g_size, \n",
    "#                  scatter_kws={'alpha': 0.05, 'color': '#A5C8E1'}, \n",
    "#                  line_kws = {'color': '#2276B4'},\n",
    "#                  lowess=True)\n",
    "# yticks =  np.arange(0,5)\n",
    "# ax.set_yticks(yticks)\n",
    "# yticklabels = [10**y for y in yticks]\n",
    "# ax.set(xlabel = 'Innovation inequality (G)',\n",
    "#        xlim = (0,1),\n",
    "#        ylabel = '# raised to adulthood',\n",
    "#        yticklabels=yticklabels)\n",
    "# sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.jointplot(x='log_breadth',y='log_depth',data=rep_df, alpha=0.01)\n",
    "# x0, x1 = g.ax_joint.get_xlim()\n",
    "# y0, y1 = g.ax_joint.get_ylim()\n",
    "# lims = [min(x0, y0), max(x1, y1)]\n",
    "# g.ax_joint.plot(lims, lims, ':k')\n",
    "# g.ax_joint.set(xlabel = 'log$_{10}$(breadth)', ylabel = 'log$_{10}$(depth)',\n",
    "#                xlim = lims, ylim = lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py3]",
   "language": "python",
   "name": "conda-env-.conda-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
