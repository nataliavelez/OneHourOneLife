{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check downloaded data for completeness\n",
    "Natalia Vélez, February 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, requests, urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from os.path import join as opj\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List local files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk through data directory and get file sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('familyDataLog.txt', 196608)\n",
      "('foodLogs/foodLog_bigserver1.onehouronelife.com/2019_01January_25_Friday.txt', 851)\n",
      "('foodLogs/foodLog_bigserver1.onehouronelife.com/2019_01January_26_Saturday.txt', 50503)\n",
      "('foodLogs/foodLog_bigserver1.onehouronelife.com/2019_01January_27_Sunday.txt', 52075)\n",
      "('foodLogs/foodLog_bigserver1.onehouronelife.com/2019_01January_28_Monday.txt', 6813)\n",
      "('foodLogs/foodLog_bigserver1.onehouronelife.com/2019_01January_29_Tuesday.txt', 50932)\n",
      "('foodLogs/foodLog_bigserver1.onehouronelife.com/2019_01January_30_Wednesday.txt', 2274)\n",
      "('foodLogs/foodLog_bigserver2.onehouronelife.com/2019_01January_29_Tuesday.txt', 144)\n",
      "('foodLogs/foodLog_bigserver2.onehouronelife.com/2019_01January_30_Wednesday.txt', 43965)\n",
      "('foodLogs/foodLog_bigserver2.onehouronelife.com/2019_01January_31_Thursday.txt', 51790)\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "def gsearch(*args): return glob.glob(opj(*args))\n",
    "\n",
    "downloaded_files = []\n",
    "data_dir = '../../data/'\n",
    "for path_obj in Path(data_dir).rglob('*.txt'):\n",
    "    path = str(path_obj)\n",
    "    f_size = os.path.getsize(path)\n",
    "    f = path.replace(data_dir, '')\n",
    "    downloaded_files.append((f, f_size))\n",
    "    \n",
    "downloaded_files.sort()\n",
    "print(*downloaded_files[:10], sep='\\n')\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assemble into dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>local_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>familyDataLog.txt</td>\n",
       "      <td>196608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foodLogs/foodLog_bigserver1.onehouronelife.com...</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foodLogs/foodLog_bigserver1.onehouronelife.com...</td>\n",
       "      <td>50503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>foodLogs/foodLog_bigserver1.onehouronelife.com...</td>\n",
       "      <td>52075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>foodLogs/foodLog_bigserver1.onehouronelife.com...</td>\n",
       "      <td>6813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  local_size\n",
       "0                                  familyDataLog.txt      196608\n",
       "1  foodLogs/foodLog_bigserver1.onehouronelife.com...         851\n",
       "2  foodLogs/foodLog_bigserver1.onehouronelife.com...       50503\n",
       "3  foodLogs/foodLog_bigserver1.onehouronelife.com...       52075\n",
       "4  foodLogs/foodLog_bigserver1.onehouronelife.com...        6813"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_df = pd.DataFrame(downloaded_files, columns=['path', 'local_size'])\n",
    "download_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List server files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohol_url = 'http://publicdata.onehouronelife.com/'\n",
    "exclude_keywords = ['..', 'foodLogs', 'curseLog'] # Directories not to download\n",
    "server = 'bigserver2' # server to download from "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all files on server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_names = []\n",
    "f_sizes = []\n",
    "\n",
    "def server_file_sizes(url, parent=''):\n",
    "\n",
    "    paths = []\n",
    "    # print('new url: %s' % url) # debug only\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.ok:\n",
    "        response_text = response.text\n",
    "    else:\n",
    "        response.raise_for_status()\n",
    "\n",
    "    # Get all valid lines from file\n",
    "    soup = BeautifulSoup(response_text, 'html.parser')\n",
    "    lines = soup.get_text().replace('\\r', '').split('\\n')\n",
    "    lines = [re.split(r' {3,}', l) for l in lines]\n",
    "    lines = [l for l in lines if len(l) == 3]\n",
    "\n",
    "    node_isdir = lambda f: f.endswith('/')\n",
    "    node_keep = lambda f: not any(kwd in f for kwd in exclude_keywords)\n",
    "\n",
    "    for l in lines:\n",
    "        f = l[0]\n",
    "\n",
    "        if not node_isdir(f):\n",
    "            paths.append((parent+f, int(l[2])))\n",
    "        else:\n",
    "            if node_keep(f):\n",
    "                print('crawl —> %s' % parent+f)\n",
    "\n",
    "                # Recursive search\n",
    "                paths += server_file_sizes(url+f, parent+f)\n",
    "                \n",
    "    return paths       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawl —> publicLifeLogData/\n",
      "crawl —> publicLifeLogData/lifeLog/\n",
      "crawl —> publicLifeLogData/lifeLog_bigserver1.onehouronelife.com/\n",
      "crawl —> publicLifeLogData/lifeLog_bigserver2.onehouronelife.com/\n",
      "crawl —> publicLifeLogData/lifeLog_server1.onehouronelife.com/\n",
      "crawl —> publicLifeLogData/lifeLog_server10.onehouronelife.com/\n",
      "crawl —> publicLifeLogData/lifeLog_server11.onehouronelife.com/\n",
      "crawl —> publicLifeLogData/lifeLog_server12.onehouronelife.com/\n",
      "crawl —> publicLifeLogData/lifeLog_server13.onehouronelife.com/\n",
      "crawl —> publicLifeLogData/lifeLog_server14.onehouronelife.com/\n",
      "crawl —> publicLifeLogData/lifeLog_server15.onehouronelife.com/\n",
      "crawl —> publicLifeLogData/lifeLog_server2.onehouronelife.com/\n",
      "crawl —> publicLifeLogData/lifeLog_server3.onehouronelife.com/\n",
      "crawl —> publicLifeLogData/lifeLog_server4.onehouronelife.com/\n",
      "crawl —> publicLifeLogData/lifeLog_server5.onehouronelife.com/\n",
      "crawl —> publicLifeLogData/lifeLog_server6.onehouronelife.com/\n",
      "crawl —> publicLifeLogData/lifeLog_server7.onehouronelife.com/\n",
      "crawl —> publicLifeLogData/lifeLog_server8.onehouronelife.com/\n",
      "crawl —> publicLifeLogData/lifeLog_server9.onehouronelife.com/\n",
      "crawl —> publicMapChangeData/\n",
      "crawl —> publicMapChangeData/bigserver2.onehouronelife.com/\n",
      "('publicLifeLogData/lifeLog_bigserver1.onehouronelife.com/2019_01January_25_Friday.txt', 118050)\n",
      "('publicLifeLogData/lifeLog_bigserver1.onehouronelife.com/2019_01January_25_Friday_names.txt', 4355)\n",
      "('publicLifeLogData/lifeLog_bigserver1.onehouronelife.com/2019_01January_26_Saturday.txt', 3377971)\n",
      "('publicLifeLogData/lifeLog_bigserver1.onehouronelife.com/2019_01January_26_Saturday_names.txt', 146267)\n",
      "('publicLifeLogData/lifeLog_bigserver1.onehouronelife.com/2019_01January_27_Sunday.txt', 3559492)\n",
      "('publicLifeLogData/lifeLog_bigserver1.onehouronelife.com/2019_01January_27_Sunday_names.txt', 151552)\n",
      "('publicLifeLogData/lifeLog_bigserver1.onehouronelife.com/2019_01January_28_Monday.txt', 514051)\n",
      "('publicLifeLogData/lifeLog_bigserver1.onehouronelife.com/2019_01January_28_Monday_names.txt', 21604)\n",
      "('publicLifeLogData/lifeLog_bigserver1.onehouronelife.com/2019_01January_29_Tuesday.txt', 2345379)\n",
      "('publicLifeLogData/lifeLog_bigserver1.onehouronelife.com/2019_01January_29_Tuesday_names.txt', 106470)\n"
     ]
    }
   ],
   "source": [
    "server_files = server_file_sizes(ohol_url)\n",
    "print(*server_files[:10], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>server_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>publicLifeLogData/lifeLog_bigserver1.onehouron...</td>\n",
       "      <td>118050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>publicLifeLogData/lifeLog_bigserver1.onehouron...</td>\n",
       "      <td>4355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>publicLifeLogData/lifeLog_bigserver1.onehouron...</td>\n",
       "      <td>3377971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>publicLifeLogData/lifeLog_bigserver1.onehouron...</td>\n",
       "      <td>146267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>publicLifeLogData/lifeLog_bigserver1.onehouron...</td>\n",
       "      <td>3559492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  server_size\n",
       "0  publicLifeLogData/lifeLog_bigserver1.onehouron...       118050\n",
       "1  publicLifeLogData/lifeLog_bigserver1.onehouron...         4355\n",
       "2  publicLifeLogData/lifeLog_bigserver1.onehouron...      3377971\n",
       "3  publicLifeLogData/lifeLog_bigserver1.onehouron...       146267\n",
       "4  publicLifeLogData/lifeLog_bigserver1.onehouron...      3559492"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_df = pd.DataFrame(server_files, columns=['path', 'server_size'])\n",
    "server_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line up file sizes on local directory and server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>local_size</th>\n",
       "      <th>server_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>familyDataLog.txt</td>\n",
       "      <td>196608</td>\n",
       "      <td>196608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>publicLifeLogData/lifeLog_bigserver1.onehouron...</td>\n",
       "      <td>118050</td>\n",
       "      <td>118050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>publicLifeLogData/lifeLog_bigserver1.onehouron...</td>\n",
       "      <td>4355</td>\n",
       "      <td>4355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>publicLifeLogData/lifeLog_bigserver1.onehouron...</td>\n",
       "      <td>3377971</td>\n",
       "      <td>3377971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>publicLifeLogData/lifeLog_bigserver1.onehouron...</td>\n",
       "      <td>146267</td>\n",
       "      <td>146267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  local_size  server_size\n",
       "0                                  familyDataLog.txt      196608       196608\n",
       "1  publicLifeLogData/lifeLog_bigserver1.onehouron...      118050       118050\n",
       "2  publicLifeLogData/lifeLog_bigserver1.onehouron...        4355         4355\n",
       "3  publicLifeLogData/lifeLog_bigserver1.onehouron...     3377971      3377971\n",
       "4  publicLifeLogData/lifeLog_bigserver1.onehouron...      146267       146267"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_comparison = pd.merge(download_df, server_df, on='path')\n",
    "file_comparison.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for discrepancies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 discrepancies found\n",
      "publicLifeLogData/lifeLog_server1.onehouronelife.com/2019_12December_02_Monday.txt\n",
      "publicLifeLogData/lifeLog_server1.onehouronelife.com/2019_12December_02_Monday_names.txt\n",
      "publicLifeLogData/lifeLog_server1.onehouronelife.com/2020_01January_07_Tuesday_names.txt\n",
      "publicLifeLogData/lifeLog_server1.onehouronelife.com/2020_06June_14_Sunday_names.txt\n",
      "publicLifeLogData/lifeLog_server10.onehouronelife.com/2019_12December_02_Monday.txt\n",
      "publicLifeLogData/lifeLog_server10.onehouronelife.com/2020_01January_09_Thursday.txt\n",
      "publicLifeLogData/lifeLog_server10.onehouronelife.com/2020_01January_09_Thursday_names.txt\n",
      "publicLifeLogData/lifeLog_server10.onehouronelife.com/2020_06June_12_Friday_names.txt\n",
      "publicLifeLogData/lifeLog_server11.onehouronelife.com/2019_12December_02_Monday.txt\n",
      "publicLifeLogData/lifeLog_server11.onehouronelife.com/2019_12December_02_Monday_names.txt\n",
      "publicLifeLogData/lifeLog_server11.onehouronelife.com/2020_01January_09_Thursday.txt\n",
      "publicLifeLogData/lifeLog_server11.onehouronelife.com/2020_01January_09_Thursday_names.txt\n",
      "publicLifeLogData/lifeLog_server11.onehouronelife.com/2020_06June_16_Tuesday_names.txt\n",
      "publicLifeLogData/lifeLog_server11.onehouronelife.com/statsCheckpoint.txt\n",
      "publicLifeLogData/lifeLog_server12.onehouronelife.com/2019_12December_02_Monday.txt\n",
      "publicLifeLogData/lifeLog_server12.onehouronelife.com/2019_12December_02_Monday_names.txt\n",
      "publicLifeLogData/lifeLog_server12.onehouronelife.com/2020_01January_09_Thursday.txt\n",
      "publicLifeLogData/lifeLog_server12.onehouronelife.com/2020_01January_09_Thursday_names.txt\n",
      "publicLifeLogData/lifeLog_server12.onehouronelife.com/2020_06June_15_Monday_names.txt\n",
      "publicLifeLogData/lifeLog_server12.onehouronelife.com/statsCheckpoint.txt\n",
      "publicLifeLogData/lifeLog_server13.onehouronelife.com/2019_12December_01_Sunday_names.txt\n",
      "publicLifeLogData/lifeLog_server13.onehouronelife.com/2020_01January_08_Wednesday_names.txt\n",
      "publicLifeLogData/lifeLog_server14.onehouronelife.com/2019_12December_02_Monday.txt\n",
      "publicLifeLogData/lifeLog_server14.onehouronelife.com/2019_12December_02_Monday_names.txt\n",
      "publicLifeLogData/lifeLog_server14.onehouronelife.com/2020_01January_09_Thursday.txt\n",
      "publicLifeLogData/lifeLog_server14.onehouronelife.com/2020_01January_09_Thursday_names.txt\n",
      "publicLifeLogData/lifeLog_server14.onehouronelife.com/2020_06June_16_Tuesday_names.txt\n",
      "publicLifeLogData/lifeLog_server15.onehouronelife.com/2019_12December_02_Monday.txt\n",
      "publicLifeLogData/lifeLog_server15.onehouronelife.com/2019_12December_02_Monday_names.txt\n",
      "publicLifeLogData/lifeLog_server15.onehouronelife.com/2020_01January_09_Thursday.txt\n",
      "publicLifeLogData/lifeLog_server15.onehouronelife.com/2020_01January_09_Thursday_names.txt\n",
      "publicLifeLogData/lifeLog_server15.onehouronelife.com/2020_06June_16_Tuesday.txt\n",
      "publicLifeLogData/lifeLog_server2.onehouronelife.com/2019_12December_02_Monday.txt\n",
      "publicLifeLogData/lifeLog_server2.onehouronelife.com/2019_12December_02_Monday_names.txt\n",
      "publicLifeLogData/lifeLog_server2.onehouronelife.com/2020_06June_16_Tuesday.txt\n",
      "publicLifeLogData/lifeLog_server2.onehouronelife.com/statsCheckpoint.txt\n",
      "publicLifeLogData/lifeLog_server3.onehouronelife.com/2020_01January_08_Wednesday_names.txt\n",
      "publicLifeLogData/lifeLog_server3.onehouronelife.com/2020_06June_16_Tuesday.txt\n",
      "publicLifeLogData/lifeLog_server3.onehouronelife.com/2020_06June_16_Tuesday_names.txt\n",
      "publicLifeLogData/lifeLog_server5.onehouronelife.com/2019_12December_02_Monday.txt\n",
      "publicLifeLogData/lifeLog_server5.onehouronelife.com/2019_12December_02_Monday_names.txt\n",
      "publicLifeLogData/lifeLog_server5.onehouronelife.com/2020_01January_09_Thursday.txt\n",
      "publicLifeLogData/lifeLog_server5.onehouronelife.com/2020_01January_09_Thursday_names.txt\n",
      "publicLifeLogData/lifeLog_server5.onehouronelife.com/2020_06June_16_Tuesday.txt\n",
      "publicLifeLogData/lifeLog_server6.onehouronelife.com/2019_12December_02_Monday.txt\n",
      "publicLifeLogData/lifeLog_server6.onehouronelife.com/2019_12December_02_Monday_names.txt\n",
      "publicLifeLogData/lifeLog_server6.onehouronelife.com/2020_01January_08_Wednesday_names.txt\n",
      "publicLifeLogData/lifeLog_server6.onehouronelife.com/2020_06June_16_Tuesday_names.txt\n",
      "publicLifeLogData/lifeLog_server6.onehouronelife.com/statsCheckpoint.txt\n",
      "publicLifeLogData/lifeLog_server7.onehouronelife.com/2019_12December_02_Monday.txt\n",
      "publicLifeLogData/lifeLog_server7.onehouronelife.com/2019_12December_02_Monday_names.txt\n",
      "publicLifeLogData/lifeLog_server7.onehouronelife.com/2020_01January_09_Thursday.txt\n",
      "publicLifeLogData/lifeLog_server7.onehouronelife.com/statsCheckpoint.txt\n",
      "publicLifeLogData/lifeLog_server8.onehouronelife.com/2019_12December_02_Monday.txt\n",
      "publicLifeLogData/lifeLog_server8.onehouronelife.com/2019_12December_02_Monday_names.txt\n",
      "publicLifeLogData/lifeLog_server8.onehouronelife.com/2020_01January_09_Thursday.txt\n",
      "publicLifeLogData/lifeLog_server8.onehouronelife.com/2020_01January_09_Thursday_names.txt\n",
      "publicLifeLogData/lifeLog_server8.onehouronelife.com/2020_06June_16_Tuesday.txt\n",
      "publicLifeLogData/lifeLog_server8.onehouronelife.com/2020_06June_16_Tuesday_names.txt\n",
      "publicLifeLogData/lifeLog_server9.onehouronelife.com/2019_12December_02_Monday.txt\n",
      "publicLifeLogData/lifeLog_server9.onehouronelife.com/2019_12December_02_Monday_names.txt\n",
      "publicLifeLogData/lifeLog_server9.onehouronelife.com/2020_01January_09_Thursday.txt\n",
      "publicLifeLogData/lifeLog_server9.onehouronelife.com/2020_01January_09_Thursday_names.txt\n",
      "publicLifeLogData/lifeLog_server9.onehouronelife.com/2020_06June_16_Tuesday.txt\n",
      "publicLifeLogData/lifeLog_server9.onehouronelife.com/2020_06June_16_Tuesday_names.txt\n"
     ]
    }
   ],
   "source": [
    "file_discrepancies = file_comparison.query('local_size != server_size')\n",
    "print('%i discrepancies found' % file_discrepancies.shape[0])\n",
    "print(*file_discrepancies.path, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove files with discrepancies for re-download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting 0 files:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files_to_delete = [opj(data_dir, f) for f in file_discrepancies.path if 'bigserver2' in f]\n",
    "print('Deleting %i files:' % len(files_to_delete))\n",
    "print(*files_to_delete, sep='\\n')\n",
    "\n",
    "for f in files_to_delete:\n",
    "    os.remove(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
