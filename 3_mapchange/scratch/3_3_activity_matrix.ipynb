{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity matrices\n",
    "Natalia VÃ©lez, June 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, re, sys, time, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse inputs (to convert to script):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing map changes between t = <1578354747, 1579713519>\n"
     ]
    }
   ],
   "source": [
    "# _, idx = sys.argv\n",
    "idx = 4\n",
    "with open('outputs/seed_changes.txt', 'r') as handle:\n",
    "    seed_data = handle.read().splitlines()\n",
    "    \n",
    "seed_data = [int(s) for s in seed_data]\n",
    "seed = seed_data[idx]\n",
    "if idx == len(seed_data)-1:\n",
    "    print('Most recent seed reached')\n",
    "    next_seed = int(time.time())\n",
    "else:\n",
    "    next_seed = seed_data[idx+1]\n",
    "    \n",
    "print('Processing map changes between t = <%i, %i>' % (seed, next_seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2805 unique items\n",
      "30\t31\t32\t33\t34\t35\t39\t40\t45\t48\t49\t53\t54\t55\t57\t58\t59\t61\t62\t63\t64\t65\t66\t67\t68\t69\t70\t71\t72\t73\t74\t75\t77\t78\t79\t80\t82\t83\t85\t86\t87\t92\t96\t99\t100\t101\t103\t104\t105\t106\n"
     ]
    }
   ],
   "source": [
    "feature_f = 'outputs/activity_features.txt'\n",
    "with open(feature_f, 'r') as handle:\n",
    "    features = handle.read().splitlines()\n",
    "    \n",
    "print('Found %i unique items' % len(features))\n",
    "print(*features[:50], sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find map change files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17 map files\n",
      "outputs/maplog/maplog_release-301_start-1578354746.tsv\n",
      "outputs/maplog/maplog_release-301_start-1578441146.tsv\n",
      "outputs/maplog/maplog_release-301_start-1578527546.tsv\n",
      "outputs/maplog/maplog_release-303_start-1578610753.tsv\n",
      "outputs/maplog/maplog_release-303_start-1578697153.tsv\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "def str_extract(pattern, s): return re.search(pattern,s).group(0)\n",
    "def seed_match(f): \n",
    "    start_t = int(str_extract('(?<=start-)[0-9]+', f))\n",
    "    return ((start_t-seed) > -2) & (start_t < next_seed)\n",
    "\n",
    "map_files = glob.glob('outputs/maplog/*.tsv')\n",
    "map_files = [f for f in map_files if seed_match(f)]\n",
    "map_files.sort()\n",
    "\n",
    "print('Found %i map files' % len(map_files))\n",
    "print(*map_files[:5], sep='\\n')\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble job matrices\n",
    "\n",
    "Helper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_crosstab(f):\n",
    "    map_df = pd.read_csv(f, sep='\\t')\n",
    "\n",
    "    # Trim invalid objects\n",
    "    map_df = map_df[map_df.player_id > 0] # No player attached to event\n",
    "    map_df = map_df[map_df.object_id != '0'] # Interact w/ empty square \n",
    "\n",
    "    # Clean up modifiers\n",
    "    map_df['object_id'] = map_df.object_id.str.replace(r'^(f)|([u-v][0-9]+$)', '')\n",
    "\n",
    "    # Convert to number\n",
    "    map_df['object_id'] = map_df['object_id'].astype(np.int64)\n",
    "    map_df['object_id'] = np.where(map_df['object_id'] > 5000, 9999, map_df['object_id'])\n",
    "    map_df['object_id'] = map_df['object_id'].astype(str)\n",
    "\n",
    "    # Make objectID and playerID into categorical variables\n",
    "    map_df['object_id'] = pd.Categorical(map_df['object_id'], categories=features)\n",
    "    map_df['player_id'] = map_df['player_id'].astype(np.int64)\n",
    "    map_df['player_id'] = pd.Categorical(map_df['player_id'])\n",
    "\n",
    "    # Co-occurrence matrix\n",
    "    map_df = map_df.reset_index(drop=True)\n",
    "    map_df = map_df[['object_id', 'player_id']]\n",
    "\n",
    "    map_occ = pd.crosstab(map_df.player_id, map_df.object_id, dropna=False)\n",
    "    mtx_map = map_occ.values\n",
    "    mtx_labels = list(map_occ.index)\n",
    "\n",
    "    return mtx_map, mtx_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function: Save array to txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_array(arr, f):\n",
    "    with open(f, 'w') as filehandle:  \n",
    "        filehandle.writelines(\"%s\\n\" % e for e in arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced33188b1534bf9834b35d233ff96e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs already exist: outputs/jobmatrix/jobmatrix_release-301_start-1578354746.txt\n",
      "Skipping file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for f in tqdm_notebook(map_files):\n",
    "    out_file = f.replace('maplog', 'jobmatrix').replace('.tsv','.txt')\n",
    "    label_file = out_file.replace('.txt', '_labels.txt')\n",
    "    \n",
    "    if os.path.exists(out_file):\n",
    "        print('Outputs already exist: %s' % out_file)\n",
    "        print('Skipping file')\n",
    "    else:\n",
    "        mtx_map, mtx_labels = map_crosstab(f)\n",
    "        np.savetxt(out_file, mtx_map, '%i')\n",
    "        write_array(mtx_labels, label_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
